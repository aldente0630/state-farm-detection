{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ea809b-7b40-4602-91a3-f24740f35fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0eb071f-fef8-4a43-8bb5-d726d3413ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import warnings\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from albumentations import (\n",
    "    Compose, \n",
    "    ShiftScaleRotate,\n",
    ")\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from utils.cam_utils import (\n",
    "    get_img_arr,\n",
    "    make_gradcam_heatmap,\n",
    "    make_gradcam_img,\n",
    ")\n",
    "from utils.common import get_elapsed_time\n",
    "from utils.data_utils import (\n",
    "    load_tfrecord_dataset,\n",
    "    mixup_dataset,\n",
    ")\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9578cc70-e9f0-41a2-bfe9-6d1c2ff2e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_img(img_arrs, labels, n_samples, label_names=None):\n",
    "    n_cols = 5\n",
    "    n_rows = n_samples // n_cols if n_samples % n_cols == 0 else n_samples // n_cols + 1\n",
    "    fig = plt.figure(figsize=(n_cols * 4, n_rows * 3))\n",
    "    for i in range(n_samples):\n",
    "        ax = fig.add_subplot(n_rows, n_cols, i + 1, xticks=[], yticks=[])\n",
    "        ax.imshow(img_arrs[i])\n",
    "        label = (\n",
    "            labels[i].decode(\"utf-8\")\n",
    "            if label_names is None\n",
    "            else label_names[f\"c{str(np.argmax(labels[i]))}\"]\n",
    "        )\n",
    "        ax.set_title(f\"Label: {label}\")\n",
    "        ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d03c27-c227-46e2-806a-ba6c877dc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "_ = config.read(os.path.join(\"..\", \"conf\", \"config.ini\"))\n",
    "\n",
    "use_pseudo_label = False\n",
    "\n",
    "project_name = config[\"project\"][\"project_name\"]\n",
    "run_name = config[\"project\"][\"run_name\"]\n",
    "raw_data_path = (\n",
    "    os.path.join(raw_data_path, \"pseudo_label\") if use_pseudo_label else raw_data_path\n",
    ")\n",
    "\n",
    "fc_size = eval(config[\"model\"][\"fc_size\"])\n",
    "img_size = eval(config[\"model\"][\"img_size\"])\n",
    "n_epochs = eval(config[\"model\"][\"n_epochs\"])\n",
    "batch_size = eval(config[\"model\"][\"batch_size\"])\n",
    "initial_learning_rate = eval(config[\"model\"][\"initial_learning_rate\"])\n",
    "first_decay_steps = eval(config[\"model\"][\"first_decay_steps\"])\n",
    "use_adamw = eval(config[\"model\"][\"use_adamw\"])\n",
    "use_swa = eval(config[\"model\"][\"use_swa\"])\n",
    "use_mixup = eval(config[\"model\"][\"use_mixup\"])\n",
    "label_smoothing = eval(config[\"model\"][\"label_smoothing\"])\n",
    "\n",
    "label_names = {\n",
    "    \"c0\": \"safe driving\",\n",
    "    \"c1\": \"texting - right\",\n",
    "    \"c2\": \"talking on the phone - right\",\n",
    "    \"c3\": \"texting - left\",\n",
    "    \"c4\": \"talking on the phone - left\",\n",
    "    \"c5\": \"operating the radio\",\n",
    "    \"c6\": \"drinking\",\n",
    "    \"c7\": \"reaching behind\",\n",
    "    \"c8\": \"hair and makeup\",\n",
    "    \"c9\": \"talking to passenger\",\n",
    "}\n",
    "\n",
    "labels = list(label_names.keys())\n",
    "num_classes = len(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4653e8c9-4be0-4199-b5a1-09fc7c25c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=project_name, reinit=False)\n",
    "\n",
    "if len(run_name) > 0:\n",
    "    wandb.run.name = run_name\n",
    "    wandb.run.save()\n",
    "\n",
    "wandb.config.update(\n",
    "    {\n",
    "        \"fc_size\": fc_size,\n",
    "        \"img_size\": img_size,\n",
    "        \"n_epochs\": n_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"initial_learning_rate\": initial_learning_rate,\n",
    "        \"first_decay_steps\": first_decay_steps,\n",
    "        \"use_adamw\": use_adamw,\n",
    "        \"use_swa\": use_swa,\n",
    "        \"use_mixup\": use_mixup,\n",
    "        \"label_smoothing\": label_smoothing,\n",
    "        \"use_pseudo_label\": use_pseudo_label,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9295fb7-dc53-41ad-b36e-9fb5cda968e3",
   "metadata": {},
   "source": [
    "## An Input Data Pipeline Configuration with *Dataset* API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d37d1d9-891c-4de2-9fd9-b35c6ce4fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw_data_path = os.path.join(raw_data_path, \"imgs\", \"train\")\n",
    "test_raw_data_path = os.path.join(raw_data_path, \"imgs\", \"test\")\n",
    "\n",
    "n_train_examples = len(\n",
    "    tf.io.gfile.glob(os.path.join(train_raw_data_path, \"*\", \"*.jpg\"))\n",
    ")\n",
    "\n",
    "train_tfrec_paths = tf.io.gfile.glob(\n",
    "    os.path.join(raw_data_path, \"tfrec\", \"train\", \"*.tfrec\")\n",
    ")\n",
    "test_img_paths = tf.io.gfile.glob(os.path.join(test_raw_data_path, \"*.jpg\"))\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        ShiftScaleRotate(\n",
    "            rotate_limit=(-20, 20),\n",
    "            scale_limit=(0.0, 0.2),\n",
    "            shift_limit_x=(-0.0625, 0.0625),\n",
    "            shift_limit_y=(-0.046875, 0.046875),\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "valid_transforms = train_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f698f52-516e-45ad-8fb1-033ab228e08d",
   "metadata": {},
   "source": [
    "## Building and Compiling a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63962c23-4570-42ac-9c4c-20e4962a15a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(\n",
    "    img_size,\n",
    "    fc_size,\n",
    "    num_classes,\n",
    "    initial_learning_rate,\n",
    "    first_decay_steps,\n",
    "    use_adamw,\n",
    "    use_swa,\n",
    "    label_smoothing,\n",
    "    verbose=False,\n",
    "):\n",
    "    effnet = tf.keras.applications.EfficientNetB0(\n",
    "        include_top=False, weights=\"imagenet\", input_shape=(img_size, img_size, 3)\n",
    "    )\n",
    "    effnet.trainable = False\n",
    "    \n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(effnet.output)\n",
    "    x = tf.keras.layers.Dense(fc_size, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(fc_size, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    output = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = tf.keras.Model(effnet.input, output)\n",
    "    \n",
    "    if verbose:\n",
    "        print(model.summary())\n",
    "\n",
    "    # For tensorflow 2.5 or later, use tf.keras.optimizers.schedules.CosineDecayRestarts.\n",
    "    lr_decayed_fn = tf.keras.experimental.CosineDecayRestarts(\n",
    "        initial_learning_rate, first_decay_steps\n",
    "    )\n",
    "    optimizer = (\n",
    "        tfa.optimizers.AdamW(lr_decayed_fn)\n",
    "        if use_adamw\n",
    "        else tfa.optimizers.RectifiedAdam(lr_decayed_fn)\n",
    "    )\n",
    "    if use_swa:\n",
    "        optimizer = tfa.optimizers.SWA(optimizer, start_averaging=0, average_period=10)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing),\n",
    "        metrics=[\"acc\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb81d0-de9a-46be-97a8-304162efa81a",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cce72d-8963-4574-9100-67cb76595569",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.25\n",
    "train_steps_per_epoch = round(n_train_examples * (1.0 - test_size) / batch_size)\n",
    "valid_steps_per_epoch = round(n_train_examples * test_size / batch_size)\n",
    "\n",
    "rs = ShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "split = rs.split(range(len(train_tfrec_paths)))\n",
    "train_index, valid_index = next(split)\n",
    "\n",
    "model_path = os.path.join(\"..\", \"models\")\n",
    "serving_path = os.path.join(\"..\", \"models\", \"serving\")\n",
    "prediction_path = os.path.join(\"..\", \"predictions\")\n",
    "version = 1\n",
    "os.makedirs(os.path.join(serving_path, str(version)), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62660882-1843-4af4-a459-cdde1d35addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_elapsed_time():\n",
    "    one_train_dataset = load_tfrecord_dataset(\n",
    "        np.array(train_tfrec_paths)[train_index],\n",
    "        img_size,\n",
    "        train_transforms,\n",
    "        batch_size,\n",
    "        num_classes=num_classes,\n",
    "        normalize=False,\n",
    "    )\n",
    "\n",
    "    if use_mixup:\n",
    "        oth_train_dataset = load_tfrecord_dataset(\n",
    "            np.array(train_tfrec_paths)[train_index],\n",
    "            img_size,\n",
    "            train_transforms,\n",
    "            batch_size,\n",
    "            num_classes=num_classes,\n",
    "            normalize=False,\n",
    "        )\n",
    "        zipped = tf.data.Dataset.zip((one_train_dataset, oth_train_dataset))\n",
    "        train_dataset = zipped.map(\n",
    "            lambda x, y: mixup_dataset(x, y, alpha=0.2),\n",
    "            num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "        )\n",
    "    else:\n",
    "        train_dataset = one_train_dataset\n",
    "\n",
    "    valid_dataset = load_tfrecord_dataset(\n",
    "        np.array(train_tfrec_paths)[valid_index],\n",
    "        img_size,\n",
    "        valid_transforms,\n",
    "        batch_size,\n",
    "        num_classes=num_classes,\n",
    "        normalize=False,\n",
    "    )\n",
    "\n",
    "    suffix = \"_to_serve\"\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            os.path.join(model_path, f\"model{suffix}.h5\"),\n",
    "            monitor=\"val_loss\",\n",
    "        ),\n",
    "        WandbCallback(),\n",
    "    ]\n",
    "\n",
    "    model = get_model(\n",
    "        img_size,\n",
    "        fc_size,\n",
    "        num_classes,\n",
    "        initial_learning_rate,\n",
    "        first_decay_steps,\n",
    "        use_adamw,\n",
    "        use_swa,\n",
    "        label_smoothing,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs=n_epochs,\n",
    "        steps_per_epoch=train_steps_per_epoch,\n",
    "        validation_data=valid_dataset,\n",
    "        validation_steps=valid_steps_per_epoch,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    tf.keras.models.save_model(\n",
    "        model,\n",
    "        serving_path,\n",
    "        overwrite=True,\n",
    "        include_optimizer=True,\n",
    "        save_format=None,\n",
    "        signatures=None,\n",
    "        options=None,\n",
    "    )\n",
    "\n",
    "print(\"The model training task has been successfully completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d05932-f920-4ac8-be31-330cc5c4ada8",
   "metadata": {},
   "source": [
    "## Model Explainability with Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fefd534-1d15-4384-b10a-cfbc44a28d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 20\n",
    "sampled_img_paths = np.random.choice(test_img_paths, n_samples)\n",
    "last_conv_layer_name = \"top_conv\"\n",
    "gradcam_img_arrs, labels = [], []\n",
    "\n",
    "for img_path in sampled_img_paths:\n",
    "    img_arr = get_img_arr(img_path, (img_size, img_size))\n",
    "    heatmap_arr, label = make_gradcam_heatmap(img_arr, model, last_conv_layer_name)\n",
    "    gradcam_img_arr = make_gradcam_img(\n",
    "        img_path,\n",
    "        heatmap_arr,\n",
    "        cam_path=os.path.join(proc_data_path, img_path.split(os.path.sep)[-1]),\n",
    "    )\n",
    "    gradcam_img_arrs.append(gradcam_img_arr / 255.0)\n",
    "    labels.append(label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe8ede-00a4-4b96-883c-95c0efa3fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_img(gradcam_img_arrs, labels, n_samples, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd9759c-0ae5-4af1-a490-0ee81190309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"image_id\", \"image\", \"label\"]\n",
    "data = []\n",
    "for img_path, label in zip(\n",
    "    sampled_img_paths,\n",
    "    labels,\n",
    "):\n",
    "    data.append(\n",
    "        [\n",
    "            img_path.split(os.path.sep)[-1],\n",
    "            wandb.Image(os.path.join(proc_data_path, img_path.split(os.path.sep)[-1])),\n",
    "            label_names[f\"c{str(label)}\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "gradcam_img_table = wandb.Table(data=data, columns=columns)\n",
    "wandb.log({\"gradcam_img_table\": gradcam_img_table})\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b406dc3-caa1-460f-9dc2-403aa23bf778",
   "metadata": {},
   "source": [
    "## *TF Serving* Testing\n",
    "* You need to download and run the docker image via `scripts/run.sh` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdbca7f-a556-4877-ad60-a22134a2887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sampled_img_arrs = np.stack(sampled_img_arrs, axis=0)\n",
    "\n",
    "data = json.dumps(\n",
    "    {\"signature_name\": \"serving_default\", \"instances\": sampled_img_arrs.tolist()}\n",
    ")\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "model_url = f\"http://localhost:8501/v{str(version)}/models/state-farm-detection:predict\"\n",
    "json_response = requests.post(model_url, data=data, headers=headers)\n",
    "predictions = json.loads(json_response.text)[\"predictions\"]\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01ec5b6-a28c-44d1-a69a-b7c0c3270f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_image(sampled_imgs, np.argmax(predictions, axis=1), n_samples, label_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
