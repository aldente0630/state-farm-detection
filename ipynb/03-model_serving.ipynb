{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9128586-958e-43bb-b205-ec004bca90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GladCam, TF Serving\n",
    "# SageMaker BiT, BYOS, Debugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea809b-7b40-4602-91a3-f24740f35fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb071f-fef8-4a43-8bb5-d726d3413ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "import sys\n",
    "import wandb\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from albumentations import (\n",
    "    Compose, \n",
    "    ShiftScaleRotate,\n",
    ")\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from utils.data_utils import (\n",
    "    identity_func,\n",
    "    load_tfrecord_dataset,\n",
    "    mixup_dataset,\n",
    ")\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d03c27-c227-46e2-806a-ba6c877dc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "_ = config.read(os.path.join(\"..\", \"conf\", \"config.ini\"))\n",
    "\n",
    "project_name = config[\"project\"][\"project_name\"]\n",
    "run_name = config[\"project\"][\"run_name\"]\n",
    "raw_data_path = config[\"project\"][\"raw_data_path\"]\n",
    "plabeled_data_path = config[\"project\"][\"plabeled_data_path\"]\n",
    "\n",
    "model_url = config[\"model\"][\"model_url\"]\n",
    "fc_size = eval(config[\"model\"][\"fc_size\"])\n",
    "img_size = eval(config[\"model\"][\"img_size\"])\n",
    "n_epochs = eval(config[\"model\"][\"n_epochs\"])\n",
    "batch_size = eval(config[\"model\"][\"batch_size\"])\n",
    "initial_learning_rate = eval(config[\"model\"][\"initial_learning_rate\"])\n",
    "first_decay_steps = eval(config[\"model\"][\"first_decay_steps\"])\n",
    "use_adamw = eval(config[\"model\"][\"use_adamw\"])\n",
    "use_mixup = eval(config[\"model\"][\"use_mixup\"])\n",
    "use_swa = eval(config[\"model\"][\"use_swa\"])\n",
    "label_smoothing = eval(config[\"model\"][\"label_smoothing\"])\n",
    "\n",
    "label_names = {\n",
    "    \"c0\": \"safe driving\",\n",
    "    \"c1\": \"texting - right\",\n",
    "    \"c2\": \"talking on the phone - right\",\n",
    "    \"c3\": \"texting - left\",\n",
    "    \"c4\": \"talking on the phone - left\",\n",
    "    \"c5\": \"operating the radio\",\n",
    "    \"c6\": \"drinking\",\n",
    "    \"c7\": \"reaching behind\",\n",
    "    \"c8\": \"hair and makeup\",\n",
    "    \"c9\": \"talking to passenger\",\n",
    "}\n",
    "\n",
    "labels = list(label_names.keys())\n",
    "num_classes = len(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4653e8c9-4be0-4199-b5a1-09fc7c25c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=project_name, reinit=False)\n",
    "\n",
    "if len(run_name) > 0:\n",
    "    wandb.run.name = run_name\n",
    "    wandb.run.save()\n",
    "    \n",
    "wandb.config = {\n",
    "    \"model_url\": model_url,\n",
    "    \"fc_size\": fc_size,\n",
    "    \"img_size\": img_size,\n",
    "    \"n_epochs\": n_epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"initial_learning_rate\": initial_learning_rate,\n",
    "    \"first_decay_steps\": first_decay_steps,\n",
    "    \"use_adamw\": use_adamw,\n",
    "    \"use_mixup\": use_mixup,\n",
    "    \"use_swa\": use_swa,\n",
    "    \"label_smoothing\": label_smoothing,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9295fb7-dc53-41ad-b36e-9fb5cda968e3",
   "metadata": {},
   "source": [
    "## The Input Data Pipeline Configuration with *Dataset* API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783390b7-465e-4b86-8774-35ca32c62b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_plabeled_data_path = os.path.join(plabeled_data_path, \"imgs\", \"train\")\n",
    "test_plabeled_data_path = os.path.join(plabeled_data_path, \"imgs\", \"test\")\n",
    "\n",
    "n_train_examples = len(\n",
    "    tf.io.gfile.glob(os.path.join(train_plabeled_data_path, \"*\", \"*.jpg\"))\n",
    ")\n",
    "test_pseudo_labeled_ids = [\n",
    "    os.path.basename(img_path)\n",
    "    for img_path in np.sort(\n",
    "        tf.io.gfile.glob(os.path.join(test_plabeled_data_path, \"*.jpg\"))\n",
    "    )\n",
    "]\n",
    "n_test_examples = len(test_pseudo_labeled_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d37d1d9-891c-4de2-9fd9-b35c6ce4fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfrec_paths = tf.io.gfile.glob(\n",
    "    os.path.join(plabeled_data_path, \"tfrec\", \"train\", \"*.tfrec\")\n",
    ")\n",
    "test_tfrec_paths = np.sort(\n",
    "    tf.io.gfile.glob(os.path.join(plabeled_data_path, \"tfrec\", \"test\", \"*.tfrec\"))\n",
    ").tolist()\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        ShiftScaleRotate(\n",
    "            rotate_limit=(-20, 20),\n",
    "            scale_limit=(0.0, 0.2),\n",
    "            shift_limit_x=(-0.0625, 0.0625),\n",
    "            shift_limit_y=(-0.046875, 0.046875),\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "valid_transforms = train_transforms\n",
    "test_transforms = identity_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f698f52-516e-45ad-8fb1-033ab228e08d",
   "metadata": {},
   "source": [
    "## Building and Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63962c23-4570-42ac-9c4c-20e4962a15a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(verbose=False):\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            hub.KerasLayer(\n",
    "                model_url, trainable=False, input_shape=(img_size, img_size, 3)\n",
    "            ),\n",
    "            tf.keras.layers.Dense(fc_size, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(fc_size, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    if verbose:\n",
    "        print(model.summary())\n",
    "\n",
    "    # For tensorflow 2.5 or later, use tf.keras.optimizers.schedules.CosineDecayRestarts.\n",
    "    lr_decayed_fn = tf.keras.experimental.CosineDecayRestarts(\n",
    "        initial_learning_rate, first_decay_steps\n",
    "    )\n",
    "    optimizer = (\n",
    "        tfa.optimizers.AdamW(lr_decayed_fn)\n",
    "        if use_adamw\n",
    "        else tfa.optimizers.RectifiedAdam(lr_decayed_fn)\n",
    "    )\n",
    "    if use_swa:\n",
    "        optimizer = tfa.optimizers.SWA(optimizer, start_averaging=0, average_period=10)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing),\n",
    "        metrics=[\"acc\"],\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb81d0-de9a-46be-97a8-304162efa81a",
   "metadata": {},
   "source": [
    "## Model Training and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cce72d-8963-4574-9100-67cb76595569",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = n_train_splits if n_train_splits > 1 else n_train_splits + 1\n",
    "train_steps_per_epoch = round(\n",
    "    n_train_examples * (n - 1) / n / batch_size\n",
    ")\n",
    "valid_steps_per_epoch = round(n_train_examples / n / batch_size)\n",
    "\n",
    "test_dataset = load_tfrecord_dataset(\n",
    "    test_tfrec_paths,\n",
    "    img_size,\n",
    "    test_transforms,\n",
    "    1,\n",
    "    shuffle=False,\n",
    "    num_classes=num_classes,\n",
    "    is_prediction=True,\n",
    ")\n",
    "\n",
    "rs = ShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "split = rs.split(range(len(train_tfrec_paths)))\n",
    "train_index, valid_index = next(split)\n",
    "\n",
    "prediction_path = os.path.join(\"..\", \"predictions\")\n",
    "saved_model_path = os.path.join(\"..\", \"saved_models\")\n",
    "\n",
    "os.makedirs(saved_model_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62660882-1843-4af4-a459-cdde1d35addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_elapsed_time():\n",
    "    one_train_dataset = load_tfrecord_dataset(\n",
    "        np.array(train_tfrec_paths)[train_index],\n",
    "        img_size,\n",
    "        train_transforms,\n",
    "        batch_size,\n",
    "        num_classes=num_classes,\n",
    "    )\n",
    "\n",
    "    if use_mixup:\n",
    "        oth_train_dataset = load_tfrecord_dataset(\n",
    "            np.array(train_tfrec_paths)[train_index],\n",
    "            img_size,\n",
    "            train_transforms,\n",
    "            batch_size,\n",
    "            num_classes=num_classes,\n",
    "        )\n",
    "        zipped = tf.data.Dataset.zip((one_train_dataset, oth_train_dataset))\n",
    "        train_dataset = zipped.map(\n",
    "            lambda x, y: mixup_dataset(x, y, alpha=0.2),\n",
    "            num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "        )\n",
    "    else:\n",
    "        train_dataset = one_train_dataset\n",
    "\n",
    "    valid_dataset = load_tfrecord_dataset(\n",
    "        np.array(train_tfrec_paths)[valid_index],\n",
    "        img_size,\n",
    "        valid_transforms,\n",
    "        batch_size,\n",
    "        num_classes=num_classes,\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            os.path.join(model_path, f\"final_model.h5\"),\n",
    "            monitor=\"val_loss\",\n",
    "        ),\n",
    "        WandbCallback(),\n",
    "    ]\n",
    "\n",
    "    model = get_model()\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs=n_epochs,\n",
    "        steps_per_epoch=train_steps_per_epoch,\n",
    "        validation_data=valid_dataset,\n",
    "        validation_steps=valid_steps_per_epoch,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    prediction = model.predict(\n",
    "        test_dataset,\n",
    "        steps=n_test_examples,\n",
    "        use_multiprocessing=True,\n",
    "    )\n",
    "\n",
    "    tf.keras.models.save_model(\n",
    "        model,\n",
    "        saved_model_path,\n",
    "        overwrite=True,\n",
    "        include_optimizer=True,\n",
    "        save_format=None,\n",
    "        signatures=None,\n",
    "        options=None,\n",
    "    )\n",
    "\n",
    "curr_result = pd.DataFrame(prediction, columns=labels, index=test_pseudo_labeled_ids)\n",
    "prev_result = pd.read_csv(os.path.join(prediction_path, \"submission.csv\"), index_col=0)\n",
    "result = pd.concat(\n",
    "    [curr_result, prev_result.loc[prev_result.index.difference(curr_result.index)]]\n",
    ")\n",
    "\n",
    "result.to_csv(os.path.join(prediction_path, \"final_submission.csv\"))\n",
    "\n",
    "print(\"The model training and prediction tasks have been successfully completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd9759c-0ae5-4af1-a490-0ee81190309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 20\n",
    "\n",
    "\n",
    "lowest_confident_ids = result.max(axis=1).sort_values()[:n_samples].index.tolist()\n",
    "lowest_confident_result = result.loc[lowest_confident_ids].values\n",
    "columns = [\"image_id\", \"image\", \"label\", \"proba\"]\n",
    "\n",
    "data = []\n",
    "for each_id, label, proba in zip(\n",
    "    lowest_confident_ids,\n",
    "    lowest_confident_result.argmax(axis=1),\n",
    "    lowest_confident_result.max(axis=1),\n",
    "):\n",
    "    data.append(\n",
    "        [\n",
    "            each_id,\n",
    "            wandb.Image(os.path.join(test_raw_data_path, each_id)),\n",
    "            label_names[f\"c{label}\"],\n",
    "            round(proba, 6),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "lowest_confident_img_table = wandb.Table(data=data, columns=columns)\n",
    "wandb.log({\"lowest_confident_img_table\": lowest_confident_img_table})\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29d1d44-6aa6-468e-b6c6-f2a31ab80ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serving test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
